version: "3.9"

services:
  train:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ../model:/model
      - ../dataset:/dataset
    image: aichat:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 4
              capabilities: [gpu]
    environment:
      - WANDB_MODE=disabled
    entrypoint: ["torchrun", "--nproc_per_node=${NPROC_PER_NODE}", "--master_port=20001", "/usr/local/lib/python3.9/dist-packages/fastchat/train/train_mem.py", "--model_name_or_path", "${MODEL_PATH}", "--data_path", "${DATA_PATH}", "--bf16", "True", "--output_dir", "${MODEL_OUTPUT}", "--num_train_epochs", "${NUM_TRAIN_EPOCHS}", "--per_device_train_batch_size", "${PER_DEVICE_TRAIN_BATCH_SIZE}","--per_device_eval_batch_size", "${PER_DEVICE_EVAL_BATCH_SIZE}", "--gradient_accumulation_steps", "2", "--evaluation_strategy", "no", "--save_strategy", "steps","--save_steps", "1200", "--save_total_limit", "10", "--learning_rate", "${LEARNING_RATE}", "--weight_decay", "0.", "--warmup_ratio", "0.03", "--lr_scheduler_type", "cosine", "--logging_steps", "1", "--fsdp", "full_shard auto_wrap","--fsdp_transformer_layer_cls_to_wrap","LlamaDecoderLayer", "--tf32","True","--model_max_length","${MODEL_MAX_LENGTH}","--gradient_checkpointing", "True", "--lazy_preprocess","True"]