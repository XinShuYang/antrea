

Step 1: Download the data.

    1. Obtain an OAuth2 token. You need to create a new token in the "Developer settings" -> "Personal access tokens" -> "Generate new token" section of your GitHub account settings.
       When creating the token, you need to choose the permissions for this token. For reading the issues of public repositories, you need the "public_repo" permission.
       Fill in your token in the token_config parameter of the issue_clawer program.

    2. Run python issue_clawer.py (Note: The program may be interrupted due to network reasons, just re-run the command).

Step 2: Filter duplicate data.

    1. Run python issue_filter.py

Step 3: Process the data into QA format, dividing the dataset into training set and validation set.

    1. issue_label_train_datasets.py is mainly used to generate the training dataset, which has three parameters '--assign-labels', '--add-labels', and '--body-prompt'.

        a.--assign-labels: This represents specifying the 'label' names, creating data that only includes the specified 'label' names.
            Example: Generate data that only contains 'bug' and 'api' labels.
                python issue_label_train_datasets.py --assign-labels bug api

        b.--add-labels: This represents adding additional label names, requiring the specification of label mapping relationships. It then generates data containing the specified labels.
            Example: Taking the 'label' of an 'issue' on 'github' as an example, add "{'triage/duplicate': 'xx',}". 'xx' represents a custom label name.
                python issue_label_train_datasets.py --add-labels "{'triage/duplicate': 'xx',}"

        c. You can also use both '--assign-labels' and '--add-labels' parameters at the same time, that is, add additional labels and use the specified labels to generate training data.
            Example: python issue_label_train_datasets.py --assign-labels bug api xx --add-labels "{'triage/duplicate': 'xx',}"

        d. Use all labels (default).
            Example: python issue_label_train_datasets.py

        e.--body-prompt: This represents whether there is a need to use chatgpt to provide a brief summary of the body part data. The program provides three prompts:['body_prompt_1','body_prompt_2','body_prompt_3'].
            Example: python issue_label_train_datasets.py 'other parameter' --body-prompt body_prompt_3

        The final generated training dataset file name is: issue_train_datasets.json, and the file name of the dataset without labels is: issue_datasets_no_label.json

    2. issue_label_train_datasets.py is mainly used to generate the validation dataset. It uses a model trained from the training set obtained by chatgpt, and uses this model to generate labels for unlabeled data, which is then used as validation dataset data.

        Example: python issue_label_evaluate_datasets.py --openai-key 'Your OpenAI key' --job-id 'The job ID of the model after the ChatGPT training has been completed.'

        The final generated validation dataset file name is: issue_evaluate_datasets.json