version: "3.9"

services:
  controller:
    build:
      context: .
      dockerfile: Dockerfile
    image: aichat:latest
    ports:
      - "21001:21001"
    entrypoint: ["python3.9", "-m", "fastchat.serve.controller", "--host", "0.0.0.0", "--port", "21001"]
  model-worker:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - /ml/model:/model
    image: aichat:latest
    ports:
      - "21002:21002"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    entrypoint: ["python3.9", "-m", "fastchat.serve.model_worker", "--model-names", "${MODEL_NAMES}", "--model-path", "${MODEL_PATH}", "--worker-address", "http://model-worker:21002", "--controller-address", "http://controller:21001", "--host", "0.0.0.0", "--port", "21002"]
  api-server:
    build:
      context: .
      dockerfile: Dockerfile
    image: aichat:latest
    ports:
      - "8000:8000"
    entrypoint: ["python3.9", "-m", "fastchat.serve.openai_api_server", "--controller-address", "http://controller:21001", "--host", "0.0.0.0", "--port", "8000"]
  debug-cli:
    build:
      context: .
      dockerfile: Dockerfile
    image: aichat:latest
    ports:
      - "7860:7860"
    command: sh -c "
        sleep ${CLI_TIMEOUT} &&
        python3.9 -m fastchat.serve.gradio_web_server --controller-url http://controller:21001 --host 0.0.0.0 --port 7860"